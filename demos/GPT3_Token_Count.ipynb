{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d392c55",
   "metadata": {},
   "source": [
    "# GPT-3 Tokenizer\n",
    "\n",
    "GPT-3 uses a byte pair encoding (BPE(https://en.wikipedia.org/wiki/Byte_pair_encoding))tokenizer. BPE is a data compression technique that replaces frequent pairs of bytes in a text with a single, previously unused byte. This technique is particularly effective for handling large vocabularies, as it allows the model to represent rare words using combinations of more common ones. The BPE tokenizer used in GPT-3 has a vocabulary size of 50,257 subword units, which includes not only words but also subwords and characters. This tokenizer is used to preprocess input data into a sequence of subwords, which are then fed into the model as a sequence of tokens.\n",
    "\n",
    "\n",
    "`tiktoken` is a fast open-source tokenizer by OpenAI.\n",
    "\n",
    "\n",
    "Splitting text strings into tokens is useful because GPT models see text in the form of tokens. Knowing how many tokens are in a text string can tell you \n",
    "\n",
    "(a) whether the string is too long for a text model to process \n",
    "\n",
    "(b) how much an OpenAI API call costs (as usage is priced by token) [In case of GPT-3 cost 0.02$/1K tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffa7adf",
   "metadata": {},
   "source": [
    "## Install Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e2f161",
   "metadata": {},
   "source": [
    "`Python >=3.8 is required`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0a1b0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1120d91",
   "metadata": {},
   "source": [
    "##  Import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ae39691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d898ea3",
   "metadata": {},
   "source": [
    "##  Load an encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34587c94",
   "metadata": {},
   "source": [
    "Encoding: `p50k_base`\tCode models: `text-davinci-002, text-davinci-003`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb557d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the number of tokens in a text string.\n",
    "def num_tokens_from_string(context, encoding_name)\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(context))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823af565",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens_from_string(\"Tell me something about yourself ..!!\", \"p50k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9da158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49976b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a7cc0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5afa517",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
